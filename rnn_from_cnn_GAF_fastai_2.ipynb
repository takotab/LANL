{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4194.3032"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "629145480/150/1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "df = pd.read_csv('data/train.csv', dtype={'acoustic_data': np.int16, 'time_to_failure': np.float32},nrows = 150*1000*500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(75000000, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acoustic_data</th>\n",
       "      <th>time_to_failure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12</td>\n",
       "      <td>1.4691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>1.4691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>1.4691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>1.4691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>1.4691</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   acoustic_data  time_to_failure\n",
       "0             12           1.4691\n",
       "1              6           1.4691\n",
       "2              8           1.4691\n",
       "3              5           1.4691\n",
       "4              8           1.4691"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "# import cv2\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "# from torchvision import transformsclass \n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 150])\n"
     ]
    }
   ],
   "source": [
    "class RnnBasedLAN(nn.Module):\n",
    "    def __init__(self, D_in, H, layers=2, dropout=0.2, bidirectional=False):\n",
    "        super(RnnBasedLAN, self).__init__()\n",
    "        self.rnn = torch.nn.LSTM(\n",
    "            D_in,\n",
    "            H,\n",
    "            num_layers=layers,\n",
    "            batch_first=True,\n",
    "            dropout=dropout,\n",
    "#             bidirectional=False,\n",
    "        )\n",
    "        self.norm = nn.LayerNorm(H)\n",
    "        self.conv = nn.Conv2d(H, 1, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"x.shape = (batch_size, seq_len, features)\"\"\"\n",
    "        x, (h_n, c_n) = self.rnn(x)\n",
    "        x = self.norm(x)\n",
    "        x = x.transpose(1,2)\n",
    "        return self.conv(x[:,:,:,None]).squeeze()\n",
    "    \n",
    "def test_rnn():\n",
    "    x = torch.rand(32,150,12)\n",
    "    mdl = RnnBasedLAN(12,64)\n",
    "    print(mdl(x).shape)\n",
    "test_rnn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 409597/409597 [00:03<00:00, 124104.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'data/images/GAF/48465000.png', 'label': 0.42099872} 75000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.420999</td>\n",
       "      <td>data/images/GAF/48465000.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.797798</td>\n",
       "      <td>data/images/GAF/16218000.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.319097</td>\n",
       "      <td>data/images/GAF/41159000.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.746998</td>\n",
       "      <td>data/images/GAF/35662000.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12.121798</td>\n",
       "      <td>data/images/GAF/58014000.png</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       label                          name\n",
       "0   0.420999  data/images/GAF/48465000.png\n",
       "1   8.797798  data/images/GAF/16218000.png\n",
       "2   2.319097  data/images/GAF/41159000.png\n",
       "3   3.746998  data/images/GAF/35662000.png\n",
       "4  12.121798  data/images/GAF/58014000.png"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "lst = []\n",
    "for i, file in enumerate(tqdm(glob.glob('data/images/GAF/*.png'))):\n",
    "    idx = int(file.split('/')[-1].split('.')[0])\n",
    "    \n",
    "    if idx < df.shape[0]:\n",
    "    \n",
    "        assert type(df.iloc[idx,1]) == np.float32, idx\n",
    "\n",
    "        lst.append({\"name\":file,'label':np.float32(df.iloc[idx,1])})\n",
    "\n",
    "print(lst[0],len(lst))\n",
    "labels_df = pd.DataFrame().from_dict(lst)\n",
    "labels_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision import *\n",
    "data = (ImageList.from_df(labels_df,\"\",'name') #Where to find the data? -> in path and its subfolders\n",
    "        .split_by_rand_pct(0.2)              #How to split in train/valid? -> use the folders\n",
    "        .label_from_df('label')\n",
    "#         .transform(tfms, size=224)       #Data augmentation? -> use tfms with a size of 64\n",
    "        .databunch())                   #Finally? -> use the defaults for conversion to ImageDataBunch\n",
    "\n",
    "learn = cnn_learner(data, models.resnet18, metrics=mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "learn.load('GAF-learner')\n",
    "print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Image (3, 224, 224), FloatItem 2.3190973)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.data.train_ds[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to add as test because default train in shuffled this way easier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_lst = ImageList.from_df(labels_df,\"\",\"name\")\n",
    "learn.data.add_test(img_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds,losses = learn.get_preds(ds_type=DatasetType.Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(75000, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>label</th>\n",
       "      <th>name</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>48465000</td>\n",
       "      <td>0.420999</td>\n",
       "      <td>data/images/GAF/48465000.png</td>\n",
       "      <td>0.646745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16218000</td>\n",
       "      <td>8.797798</td>\n",
       "      <td>data/images/GAF/16218000.png</td>\n",
       "      <td>7.968527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41159000</td>\n",
       "      <td>2.319097</td>\n",
       "      <td>data/images/GAF/41159000.png</td>\n",
       "      <td>3.073750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35662000</td>\n",
       "      <td>3.746998</td>\n",
       "      <td>data/images/GAF/35662000.png</td>\n",
       "      <td>3.480164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>58014000</td>\n",
       "      <td>12.121798</td>\n",
       "      <td>data/images/GAF/58014000.png</td>\n",
       "      <td>12.320049</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        idx      label                          name       pred\n",
       "0  48465000   0.420999  data/images/GAF/48465000.png   0.646745\n",
       "1  16218000   8.797798  data/images/GAF/16218000.png   7.968527\n",
       "2  41159000   2.319097  data/images/GAF/41159000.png   3.073750\n",
       "3  35662000   3.746998  data/images/GAF/35662000.png   3.480164\n",
       "4  58014000  12.121798  data/images/GAF/58014000.png  12.320049"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = []\n",
    "for pred, row in zip(preds, labels_df.iterrows()):\n",
    "    row = dict(row[1])\n",
    "    row[\"pred\"] = pred.numpy()[0]\n",
    "    row['idx'] = int(row[\"name\"].split('/')[-1].split('.')[0])\n",
    "    predictions.append(row)\n",
    "pred_df = pd.DataFrame().from_dict(predictions)\n",
    "pred_df.to_csv('data/predictions_.csv')\n",
    "print(pred_df.shape)\n",
    "pred_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(75000, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>idx</th>\n",
       "      <th>label</th>\n",
       "      <th>name</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>48465000</td>\n",
       "      <td>0.420999</td>\n",
       "      <td>data/images/GAF/48465000.png</td>\n",
       "      <td>0.646745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>16218000</td>\n",
       "      <td>8.797798</td>\n",
       "      <td>data/images/GAF/16218000.png</td>\n",
       "      <td>7.968527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>41159000</td>\n",
       "      <td>2.319097</td>\n",
       "      <td>data/images/GAF/41159000.png</td>\n",
       "      <td>3.073750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>35662000</td>\n",
       "      <td>3.746998</td>\n",
       "      <td>data/images/GAF/35662000.png</td>\n",
       "      <td>3.480164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>58014000</td>\n",
       "      <td>12.121798</td>\n",
       "      <td>data/images/GAF/58014000.png</td>\n",
       "      <td>12.320049</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0       idx      label                          name       pred\n",
       "0           0  48465000   0.420999  data/images/GAF/48465000.png   0.646745\n",
       "1           1  16218000   8.797798  data/images/GAF/16218000.png   7.968527\n",
       "2           2  41159000   2.319097  data/images/GAF/41159000.png   3.073750\n",
       "3           3  35662000   3.746998  data/images/GAF/35662000.png   3.480164\n",
       "4           4  58014000  12.121798  data/images/GAF/58014000.png  12.320049"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df = pd.read_csv('data/predictions_.csv')\n",
    "print(pred_df.shape)\n",
    "pred_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our RNN is based on 1 features\n"
     ]
    }
   ],
   "source": [
    "def create_X(last_index, n_steps=150, step_length=1000):\n",
    "       \n",
    "    assert last_index - n_steps * step_length >= 0\n",
    "    result=[]\n",
    "    y = []\n",
    "    for i in range(n_steps):\n",
    "        _idx = i*step_length\n",
    "        \n",
    "        c_data = dict(pred_df.loc[pred_df.idx == _idx,:])\n",
    "        y.append(c_data['label'])\n",
    "        result.append(c_data['pred'])\n",
    "    assert len(result) == n_steps\n",
    "    return np.concatenate(result)[:,None].astype(np.float32), np.concatenate(y).astype(np.float32)\n",
    "\n",
    "# Query \"create_X\" to figure out the number of features\n",
    "n_features = create_X(df.shape[0] ,n_steps=10)[0].shape[1]\n",
    "print(\"Our RNN is based on %i features\"% n_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 354/499 [00:58<00:24,  5.86it/s]"
     ]
    }
   ],
   "source": [
    "\n",
    "class LAN_GAF_Dataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        last_indexs,\n",
    "        seq_len=150,\n",
    "        rand=False\n",
    "#         overlap\n",
    "    ):\n",
    "        self.last_indexs =  last_indexs\n",
    "        self.seq_len = seq_len\n",
    "        self.rand = rand\n",
    "        \n",
    "    def __len__(self):\n",
    "        return int(len(self.last_indexs)/150)-1\n",
    "        \n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        idx += 1\n",
    "        idx *= 150\n",
    "        idx = self.last_indexs[idx]\n",
    "#         print(idx)\n",
    "        x, y = create_X(last_index=idx, n_steps=self.seq_len, step_length=1000)\n",
    "        return x,y\n",
    "    \n",
    "ds = LAN_GAF_Dataset(np.array(pred_df.loc[:,'idx']))\n",
    "for i in tqdm(range(len(ds))):\n",
    "    dct = [o.shape for o in ds[i]]\n",
    "    \n",
    "    \n",
    "print(dct)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75000, 5)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9450000 9600000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(150,)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = 150*1000*64\n",
    "print(idx- 150*1000,idx)\n",
    "np.arange(idx - 150*1000,idx,1000).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from ignite.engine import Events, create_supervised_trainer, create_supervised_evaluator\n",
    "# between train and validation\n",
    "second_earthquake = 50085877/1000\n",
    "\n",
    "train_dl = DataLoader(LAN_GAF_Dataset(np.array(pred_df.loc[second_earthquake:,'idx'])), batch_size= 64, num_workers=4)\n",
    "valid_dl = DataLoader(LAN_GAF_Dataset(np.array(pred_df.loc[:second_earthquake,'idx'])), batch_size= 32, num_workers=2)\n",
    "\n",
    "# optimizer = torch.optim.Adam(model.parameters())\n",
    "loss = torch.nn.MSELoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def last_step_acc(preds, targs):\n",
    "    return torch.mean(torch.abs( preds[:,-1]-targs[:,-1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.basic_data import *\n",
    "from fastai.basic_train import Learner\n",
    "from fastai.train import fit_one_cycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_bunch = DataBunch(train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = Learner(data_bunch, RnnBasedLAN(1,8), loss_func=loss, metrics = [last_step_acc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Total time: 00:38 <p><table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>last_step_acc</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.017366</td>\n",
       "      <td>0.530458</td>\n",
       "      <td>0.688184</td>\n",
       "      <td>00:38</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(1,0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5304581, tensor(0.6882)]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3Xl4lPW5//H3TRIIEPYEBRKWKgrITkBbNxBr0SqIRQm/2la70Hpq7dFjf6W2P7ertp7WY63Vqx6sy7HnmIg7Lhy0laq1KgmICMEFLSZhDVFZhEAC9++PefI4xCxDyJPJ8nldVy5mnvnOM/c3E+YzzzL3mLsjIiIC0CnZBYiISOuhUBARkZBCQUREQgoFEREJKRRERCSkUBARkZBCQUREQgoFEREJKRRERCSUmuwCDldmZqYPHTo02WWIiLQpK1as2O7uWY2Na3OhMHToUIqKipJdhohIm2JmHyYyTruPREQkpFAQEZGQQkFEREJt7piCiLQfVVVVlJWVUVlZmexS2o309HSys7NJS0tr0v0VCiKSNGVlZfTo0YOhQ4diZskup81zdyoqKigrK2PYsGFNWod2H4lI0lRWVtKvXz8FQjMxM/r163dEW14KBRFJKgVC8zrS32eH2X307tZdPL16Mz3TU8nokkqP9DR6pKfG/cSud01L0R+piHRYHSoU/vDCezT2ldQpnYwetYLj80FSd6DUjMnokkpKJwWLSGtXUVHB9OnTAdiyZQspKSlkZcU+9Lt8+XI6d+7c6DouvfRSFixYwPHHHx9prS2lw4TCuWMHcs7oAezeX83uymp2VVazq7KKXZXV7KysYve+Q5ftrqxmZ3B90yeV7NpXFd6v+mAjyQJkdKkJidQ6giSNHsFtGXHLe9YKl86p2rsnEqV+/fqxatUqAK6//noyMjK4+uqrDxnj7rg7nTrV/f/xvvvui7zOltRhQgGgUyejZ3oaPdObdqoWxP5AKqsOxsKjVpB89m+tgNlXzSd79lP60R52Vlaze18VlVUHG32sLqmdPr9V0iUIjiBcegbLM7qk1RlA2h0mcvjWr1/PzJkzmTBhAm+88QbPP/88N9xwAytXrmTv3r3MnTuXa6+9FoBTTjmFO+64g9GjR5OZmckPfvADlixZQrdu3XjyySfp379/kmdzeDpUKDQHM6Nr5xS6dk7hSJ7q/dUHg62Tqs+FyK64LZedtcKlfNfucPzufdWNPk7N7rD44OiZ/tluroZ2h4VjuqTSSbvDJGI3PLWW4k07m3Wdowb25LrzTmjSfd9++20eeOABcnNzAbj55pvp27cv1dXVTJs2jTlz5jBq1KhD7rNjxw5OP/10br75Zq666iruvfdeFixYcMTzaEkKhSTpnNqJvqmd6du98X2W9Tlw0Pl0f127vQ4NmvhdYzsrq4PdYbvCMQcS3B32WbjUcXylVsBkxO0OqwkX7Q6TtuSYY44JAwEgPz+fe+65h+rqajZt2kRxcfHnQqFr166cffbZAEyaNImXX365RWtuDgqFNizlkN1hXZu0Dndnb9WBQ46h1GyFfHbMJQiXmqDZV8XHcbvDdlVWsa868d1hPcPdX7HdYeMH9+ZrE7PJ6tGlSXOQ9qGp7+ij0r179/Dye++9x+9//3uWL19O7969ufjii+v8LED8gemUlBSqqxvfmm9tFAodnJnRrXMq3Tqn0r9n09ezv/pgrd1en22t7K65XMfuss2fVPK/a7dwy9J3OHPkUeRNyeHU4Vk6e0talZ07d9KjRw969uzJ5s2bWbp0KTNmzEh2WZFQKEiz6JzaiX4ZXeiXcfjv9tdv281DhSU8unIj/7t2C4N6d+XC3GwuzM1hUO+mbQGJNKeJEycyatQoRowYwZAhQzj55JOTXVJkzBs7cb+Vyc3NdX3JTvu0v/ogzxdvpaCwhJff244ZnH5cFnmTBzN9ZH/SUnRMor1Zt24dI0eOTHYZ7U5dv1czW+HuufXcJaQtBWk1Oqd24qtjB/DVsQMo/WgPi4pKWVRUyg/+ewWZGV2YMymbuZNzGJbZvfGViUiTKBSkVcrp241/O+t4fjx9OC++W07+8lLufvkD7nrxfU76Ql/mTRnMV044mvS0lGSXKtKuKBSkVUtN6cT0kUcxfeRRbN1ZySMryigoLOHHBavo1TWN2RMGMW/KYI4/ukeySxVpFxQK0mYc1TOdH047lstOP4ZXP6ggf3kJD75ewv3/2MD4nN7Mm5LDuWMH0r2L/qxFmkr/e6TN6dTJOPnYTE4+NpOPPt3PYyvLKCgs5aePvsWNTxUzc/xA5k4ezLjsXmrxIXKYFArSpvXt3pnvnvoFvnPKMFaWfEz+8lIef2Mj+ctLGXF0D+ZNGcz54wfRq1vT+12JdCQ6x0/aBTNj0pC+3HLhOJb//Ex+ef5oUlOM6xavZcqv/sKVD63itQ8qaGunYEu0pk2bxtKlSw9Zdtttt3HZZZfVe5+MjAwANm3axJw5c+ocM3XqVBo7df62225jz5494fVzzjmHTz75JNHSI6NQkHanZ3oaF580hKd/dCpP/+gULszN5i/FW8lb+BrT/+NF/vPF99m+e1+yy5RWYN68eRQUFByyrKCggHnz5jV634EDB/LII480+bFrh8Kzzz5L7969m7y+5hJZKJjZvWa2zczW1HP7CDN71cz2mdnVdY0ROVKjB/Xil+eP4fWfT+eWC8fRt3tnfr3kbU761V+57L9X8OK75Qk1BJT2ac6cOTzzzDPs378fgA0bNrBp0yYmTJjA9OnTmThxImPGjOHJJ5/83H03bNjA6NGjAdi7dy95eXmMHDmS2bNns3fv3nDcZZddRm5uLieccALXXXcdALfffjubNm1i2rRpTJs2DYChQ4eyfft2AG699VZGjx7N6NGjue2228LHGzlyJN/73vc44YQTOOussw55nOYS5TGF+4E7gAfquf0j4Arg/AhrEAGgW+dU5kzKZs6kbNZv20XB8lIeXVnGkjWxthoX5eZwYW42A9VWI3mWLIAtbzXvOo8eA2ffXO/Nffv2ZcqUKSxZsoRZs2ZRUFDARRddRNeuXXn88cfp2bMn27dv56STTmLmzJn1nrjwxz/+kW7durFu3TpWr17NxIkTw9tuuukm+vbty4EDB5g+fTqrV6/miiuu4NZbb2XZsmVkZmYesq4VK1Zw33338frrr+PunHjiiZx++un06dOH9957j/z8fO6++24uuugiHn30US6++OLm+V0FIttScPeXiL3w13f7NncvBKqiqkGkLsf278Evzh3Fa9dM547/M4Fhmd353V/e5ZR/f4FL71vO0rVbqDrQeNdXaR/idyHV7Dpyd6655hrGjh3LmWeeycaNG9m6dWu963jppZfCF+exY8cyduzY8LZFixYxceJEJkyYwNq1aykuLm6wnr///e/Mnj2b7t27k5GRwQUXXBC24B42bBjjx48HYq25N2zYcCRTr1ObOPvIzOYD8wEGDx6c5GqkveiSmsK5Ywdy7tiBlFTE2mo8vKKU7/95BVk9grYauTkMVVuNltHAO/oozZo1iyuvvJKVK1eyZ88eJk2axP333095eTkrVqwgLS2NoUOH1tkquzH//Oc/ueWWWygsLKRPnz5ccsklTVpPjS5dPms4mZKSEsnuozZxoNndF7p7rrvn1nyptkhzGtyvG1d/5Xhe+ekZ/OmbuYzL7sV/vvg+U2/5G/MWvsaTqzZSWXUg2WVKBDIyMpg2bRrf/va3wwPMO3bsoH///qSlpbFs2TI+/PDDBtdx2mmn8eCDDwKwZs0aVq9eDcRabnfv3p1evXqxdetWlixZEt6nR48e7Nq163PrOvXUU3niiSfYs2cPn376KY8//jinnnpqc023UW1iS0GkpaSmdOLMUUdx5qij2LKjkkdWlPJQUSk/LlhF726xthp5k9VWo72ZN28es2fPDncjff3rX+e8885jzJgx5ObmMmLEiAbvf9lll3HppZcycuRIRo4cyaRJkwAYN24cEyZMYMSIEeTk5BzScnv+/PnMmDGDgQMHsmzZsnD5xIkTueSSS5gyZQoA3/3ud5kwYUIku4rqEmnrbDMbCjzt7qMbGHM9sNvdb0lknWqdLS3t4EHnH+9XkF9YwnNrt1B1wJkwuDfzJg/mq2MHqK3GEVDr7Gi0ytbZZpYPTAUyzawMuA5IA3D3u8zsaKAI6AkcNLN/BUa5e/N+c7fIEerUyThleCanDM+kYve+4BPTJfzfR1dz49PFnDduIHmTcxirthrSDkQWCu7e4Kc/3H0LkB3V44tEoV9Gl7CtxooPa9pqlJG/vISRA3oyb0oOs8YPoldXtdWQtknbvSJNYGbkDu1L7tC+XHveKBa/uYmC5SVc++RabnpmHV8dM4C5k3OYMqyvth4a4e76HTWjIz0koFAQOUK9uqbxjZOG8I2ThrBm4w7yl5fw5KpNPPbGRr6Q1Z28yTlcMDGbzCZ8f3V7l56eTkVFBf369VMwNAN3p6KigvT09CavQ9/RLBKBPfureWb1ZgoKS1nx4cekpRhfHnUUcycP5tRjM+nUSS+AAFVVVZSVlR3RuftyqPT0dLKzs0lLO3QXZqIHmhUKIhF7d+suHios5bGVZXy8p4pBvbsyd3KsrcaAXmqrIS1DoSDSyuyrPsBza7dSUFjCK+sr6GQw9fj+5E3OYdqI/qSltInPkkobpVAQacVKKvbwUFEJDxeVsW3XPrJ6dOHCSdnMnZzDkH5qqyHNT6Eg0gZUHzjIsnfKKVhewrJ3tnHQ4UvH9GPu5By+csLRpKelJLtEaScUCiJtzJYdlTxcFGurUfbxXnp3S+OCCdnkTcnhuKPUVkOOjEJBpI06eNB55f3tFCwv5bniWFuNiYN7kzd5MOeOG0C3zjqTXA6fQkGkHdi+ex+Pr9xIfmEJH5R/SkaXVGaOj7XVGDNIbTUkcQoFkXbE3Sn68GPyl5fwzOrN7Ks+yKigrcZMtdWQBCgURNqpHXurWLxqI/nLSynevJP0tE6cM2YAeZMHM3loH209SJ0UCiLtnLuzZuNO8gtLWLxqE7v3VXNMVnfyJg/mgomD6Ke2GhJHoSDSgXy6r5pn3tpMwfISVpZ8QlqKcdaoo5k7OYdT1FZDUCiIdFjvbAnaarxRxid7qsju05W5uTnMUVuNDk2hINLBVVYd4LnirRQsL+Ef78faakw7vj9zJ+dwxoj+pKqtRoeS9G9eE5HkSk9LYea4gcwcN5AN2z9lUVEpD68o469vb6N/jy5cmJvN3NzBDO7XLdmlSiuiLQWRDqTqwEGWvb2NgsJS/ha01Tj52H7MnTyYr5xwFF1S1VajvdLuIxFp0OYde3m4qIyHCkvZ+Mle+nRL44KJ2eRNzmG42mq0OwoFEUnIgYPOK+u3U1BYwvPFW6k64Ewa0ofb501gUG8dmG4vdExBRBKS0sk47bgsTjsui+279/HYyjL+si523EE6Hm0piIh0AIluKUR2TpqZ3Wtm28xsTT23m5ndbmbrzWy1mU2MqhYREUlMlCcq3w/MaOD2s4Hhwc984I8R1iIiIgmILBTc/SXgowaGzAIe8JjXgN5mNiCqekREpHHJ/EjjIKA07npZsOxzzGy+mRWZWVF5eXmLFCci0hG1ic+5u/tCd89199ysrKxklyMi0m4lMxQ2Ajlx17ODZSIikiTJDIXFwDeDs5BOAna4++Yk1iMi0uFF9uE1M8sHpgKZZlYGXAekAbj7XcCzwDnAemAPcGlUtYiISGIiCwV3n9fI7Q78MKrHFxGRw9cmDjSLiEjLUCiIiEhIoSAiIiGFgoiIhBQKIiISUiiIiEhIoSAiIiGFgoiIhBQKIiISUiiIiEhIoSAiIiGFgoiIhBQKIiISUiiIiEhIoSAiIiGFgoiIhBQKIiISUiiIiEhIoSAiIiGFgoiIhBQKIiISUiiIiEgo0lAwsxlm9o6ZrTezBXXcPsTM/mpmq83sb2aWHWU9IiLSsMhCwcxSgDuBs4FRwDwzG1Vr2C3AA+4+FrgR+HVU9YiISOOi3FKYAqx39w/cfT9QAMyqNWYU8EJweVkdt4uISAuKMhQGAaVx18uCZfHeBC4ILs8GephZvwhrEhGRBiT7QPPVwOlm9gZwOrAROFB7kJnNN7MiMysqLy9v6RpFRDqMKENhI5ATdz07WBZy903ufoG7TwB+Hiz7pPaK3H2hu+e6e25WVlaEJYuIdGxRhkIhMNzMhplZZyAPWBw/wMwyzaymhp8B90ZYj4iINCKyUHD3auByYCmwDljk7mvN7EYzmxkMmwq8Y2bvAkcBN0VVj4iINM7cPdk1HJbc3FwvKipKdhkiIm2Kma1w99zGxiX7QLOIiLQiCgUREQklFApmdoyZdQkuTzWzK8ysd7SliYhIS0t0S+FR4ICZHQssJHaq6YORVSUiIkmRaCgcDM4mmg38wd1/AgyIriwREUmGREOhyszmAd8Cng6WpUVTkoiIJEuioXAp8EXgJnf/p5kNA/4cXVkiIpIMqYkMcvdi4AoAM+sD9HD3f4+yMBERaXmJnn30NzPraWZ9gZXA3WZ2a7SliYhIS0t091Evd99JrM31A+5+InBmdGWJiEgyJBoKqWY2ALiIzw40i4hIO5NoKNxIrLHd++5eaGZfAN6LriwREUmGRA80Pww8HHf9A+BrURUlIiLJkeiB5mwze9zMtgU/j5pZdtTFiYhIy0p099F9xL4gZ2Dw81SwTERE2pFEQyHL3e9z9+rg535A34spItLOJBoKFWZ2sZmlBD8XAxVRFiYiIi0v0VD4NrHTUbcAm4E5wCUR1SQiIkmSUCi4+4fuPtPds9y9v7ufj84+EhFpd47km9euarYqRESkVTiSULBmq0JERFqFIwkFb7YqRESkVWgwFMxsl5ntrONnF7HPKzTIzGaY2Ttmtt7MFtRx+2AzW2Zmb5jZajM75wjmIiIiR6jBNhfu3qOpKzazFOBO4MtAGVBoZouD72ao8Qtgkbv/0cxGAc8CQ5v6mCIicmSOZPdRY6YA6939A3ffDxQAs2qNcaBncLkXsCnCekREpBEJNcRrokFAadz1MuDEWmOuB54zsx8B3dF3NIiIJFWUWwqJmAfc7+7ZwDnAn83sczWZ2XwzKzKzovLy8hYvUkSko4gyFDYCOXHXs4Nl8b4DLAJw91eBdCCz9orcfaG757p7blaWWi6JiEQlylAoBIab2TAz6wzkEeu0Gq8EmA5gZiOJhYI2BUREkiSyUHD3auByYt/Yto7YWUZrzexGM5sZDPs34Htm9iaQD1zi7vr8g4hIkkR5oBl3f5bYaabxy66Nu1wMnBxlDSIikrhkH2gWEZFWRKEgIiIhhYKIiIQUCiIiElIoiIhISKEgIiIhhYKIiIQUCiIiElIoiIhISKEgIiIhhYKIiIQUCiIiElIoiIhISKEgIiIhhYKIiIQUCiIiElIoiIhISKEgIiIhhYKIiIQUCiIiElIoiIhISKEgIiKhSEPBzGaY2Ttmtt7MFtRx++/MbFXw866ZfRJlPSIi0rDUqFZsZinAncCXgTKg0MwWu3txzRh3vzJu/I+ACVHVIyIijYtyS2EKsN7dP3D3/UABMKuB8fOA/AjrERGRRkQZCoOA0rjrZcGyzzGzIcAw4IUI6xERkUa0lgPNecAj7n6grhvNbL6ZFZlZUXl5eQuXJiLScUQZChuBnLjr2cGyuuTRwK4jd1/o7rnunpuVldWMJYqISLwoQ6EQGG5mw8ysM7EX/sW1B5nZCKAP8GqEtYiISAIiCwV3rwYuB5YC64BF7r7WzG40s5lxQ/OAAnf3qGoREZHERHZKKoC7Pws8W2vZtbWuXx9lDSIikrjWcqBZRERaAYWCiIiEFAoiIhJSKIiISEihICIiIYWCiIiEFAoiIhJSKIiISEihICIiIYWCiIiEFAoiIhJSKIiISEihICIiIYWCiIiEFAoiIhJSKIiISEihICIiIYWCiIiEFAoiIhJSKIiISEihICIiIYWCiIiEFAoiIhKKNBTMbIaZvWNm681sQT1jLjKzYjNba2YPRlmPiIg0LDWqFZtZCnAn8GWgDCg0s8XuXhw3ZjjwM+Bkd//YzPpHVY+IiDQuyi2FKcB6d//A3fcDBcCsWmO+B9zp7h8DuPu2COsREZFGRBkKg4DSuOtlwbJ4xwHHmdkrZvaamc2oa0VmNt/MisysqLy8PKJyRUQk2QeaU4HhwFRgHnC3mfWuPcjdF7p7rrvnZmVltXCJIiIdR5ShsBHIibueHSyLVwYsdvcqd/8n8C6xkBARkSSIMhQKgeFmNszMOgN5wOJaY54gtpWAmWUS2530QYQ1iYhIAyILBXevBi4HlgLrgEXuvtbMbjSzmcGwpUCFmRUDy4CfuHtFVDWJiEjDzN2TXcNhyc3N9aKiomSXISLSppjZCnfPbWxcsg80i4hIK6JQEBGRkEJBRERCCgUREQkpFEREJKRQEBGRkEJBRERCCgUREQkpFEREJKRQEBGRkEJBRERCCgUREQkpFEREJKRQEBGRkEJBRERCCgUREQkpFEREJKRQEBGRkEJBRERCCgUREQkpFEREJKRQEBGRUKShYGYzzOwdM1tvZgvquP0SMys3s1XBz3ejrEdERBqWGtWKzSwFuBP4MlAGFJrZYncvrjX0IXe/PKo6REQkcVFuKUwB1rv7B+6+HygAZkX4eCIicoSiDIVBQGnc9bJgWW1fM7PVZvaImeXUtSIzm29mRWZWVF5eHkWtIiJChLuPEvQUkO/u+8zs+8B/AWfUHuTuC4GFAMExiA+b+HiZwPamFtvKaC6tU3uZS3uZB2guNYYkMijKUNgIxL/zzw6Whdy9Iu7qn4DfNLZSd89qakFmVuTuuU29f2uiubRO7WUu7WUeoLkcrih3HxUCw81smJl1BvKAxfEDzGxA3NWZwLoI6xERkUZEtqXg7tVmdjmwFEgB7nX3tWZ2I1Dk7ouBK8xsJlANfARcElU9IiLSuEiPKbj7s8CztZZdG3f5Z8DPoqyhloUt+FhR01xap/Yyl/YyD9BcDou5e9SPISIibYTaXIiISKhdhkIC7TW6mNlDwe2vm9nQlq8yMe2lVYiZ3Wtm28xsTT23m5ndHsxztZlNbOkaE5XAXKaa2Y645+TausYlm5nlmNkyMys2s7Vm9uM6xrSJ5yXBubSV5yXdzJab2ZvBXG6oY0x0r2Hu3q5+iB3Ufh/4AtAZeBMYVWvMvwB3BZfziLXaSHrtTZzLJcAdya41gbmcBkwE1tRz+znAEsCAk4DXk13zEcxlKvB0sutMYB4DgInB5R7Au3X8fbWJ5yXBubSV58WAjOByGvA6cFKtMZG9hrXHLYVE2mvMIvZBOYBHgOlmZi1YY6LaTasQd3+J2Blm9ZkFPOAxrwG9a52y3GokMJc2wd03u/vK4PIuYqeE1+460CaelwTn0iYEv+vdwdW04Kf2wd/IXsPaYygk0l4jHOPu1cAOoF+LVHd4mq1VSBuQ6Fzbii8Gm/9LzOyEZBfTmGD3wwRi70rjtbnnpYG5QBt5XswsxcxWAduA59293ueluV/D2mModDRPAUPdfSzwPJ+9e5DkWQkMcfdxwB+AJ5JcT4PMLAN4FPhXd9+Z7HqORCNzaTPPi7sfcPfxxDpBTDGz0S312O0xFBptrxE/xsxSgV5ABa1PQq1C3H1fcPVPwKQWqq25JfK8tQnuvrNm899jn9VJM7PMJJdVJzNLI/Yi+j/u/lgdQ9rM89LYXNrS81LD3T8BlgEzat0U2WtYewyFRttrBNe/FVyeA7zgwRGbVqYjtQpZDHwzONvlJGCHu29OdlFNYWZH1+zfNbMpxP6ftbo3HUGN9wDr3P3Weoa1ieclkbm0oecly8x6B5e7EvtOmrdrDYvsNSzZXVKbnSfWXuMe4M9mtp7YAcO85FVcvwTn0iZahZhZPrGzPzLNrAy4jtgBNNz9LmKffD8HWA/sAS5NTqWNS2Auc4DLzKwa2AvktdI3HScD3wDeCvZfA1wDDIY297wkMpe28rwMAP7LYl9U1glY5O5Pt9RrmD7RLCIiofa4+0hERJpIoSAiIiGFgoiIhBQKIiISUiiIiEhIoSCtjpkdCLpYvmlmK83sS42M721m/5LAev9mZu3iu3qbi5ndb2Zzkl2HtB4KBWmN9rr7+KAdwc+AXzcyvjexrpGtUvCJU5E2QaEgrV1P4GOI9bUxs78GWw9vmVlNx9ibgWOCrYvfBmN/Gox508xujlvfhUGv+nfN7NRgbIqZ/dbMCoPGgt8Plg8ws5eC9a6pGR/PzDaY2W+Cx1puZscGy+83s7vM7HXgN2bW18yeCNb/mpmNjZvTfcH9V5vZ14LlZ5nZq8FcHw56+mBmN1vsOwNWm9ktwbILg/reNLOXGpmTmdkdFvuOjr8A/ZvzyZK2T+9gpDXqGnwqNZ3YpzvPCJZXArPdfafFeta8ZmaLgQXA6KCBGGZ2NrHWwie6+x4z6xu37lR3n2Jm5xD7JPKZwHeItW+YbGZdgFfM7DngAmCpu98UfLq0Wz317nD3MWb2TeA24NxgeTbwJXc/YGZ/AN5w9/PN7AzgAWA88P9q7h/U3ieY2y+AM939UzP7KXCVmd0JzAZGuLvXtEIArgW+4u4b45bVN6cJwPHAKOAooBi4N6FnRToEhYK0RnvjXuC/CDxgsS6RBvzKzE4DDhJrH3xUHfc/E7jP3fcAuHv8dx/UNEpbAQwNLp8FjI3bt94LGE6s99S9Fmu09oS7r6Ju+XH//i5u+cPufiC4fArwtaCeF8ysn5n1DGoNWxS4+8dmdi6xF+1XLNaqpzPwKrH2yJXAPWb2NPB0cLdXgPvNbFHc/Oqb02lAflDXJjN7oZ45SQelUJBWzd1fDd45ZxHrwZMFTHL3KjPbQGxr4nDUdJQ9wGd//wb8yN2X1h4cBNBXib3o3uruD9RVZj2XPz3M2sKHJdZDf14d9UwBphPr43M5cIa7/8DMTgzqXGFmk+qbU7CFJFIvHVOQVs3MRhBrBlhB7N3utiAQpgFDgmG7iH0FY43ngUvNrFuwjvjdR3VZSqxRWlow/jgz625mQ4Ct7n43sbbk9X0/8dy4f1+tZ8zLwNeD9U8Ftgf9/p8Hfhg33z7Aa8DJccdjwqPIAAABE0lEQVQnugc1ZQC9grbPVwLjgtuPcffX3f1aoJxYS+U65wS8BMwNjjkMAKY18ruRDkZbCtIa1RxTgNg73m8F++X/B3jKzN4CigjaCbt7hZm9YmZrgCXu/hMzGw8Umdl+Yp0+r2ng8f5EbFfSSovtrykHzifWCfUnZlYF7Aa+Wc/9+5jZamJbIZ97dx+4ntiuqNXEuo3WtD3+JXBnUPsB4AZ3f8zMLgHyg+MBEDvGsAt40szSg9/LVcFtvzWz4cGyvxL7Lu/V9czpcWLHaIqBEuoPMemg1CVV5AgEu7By3X17smsRaQ7afSQiIiFtKYiISEhbCiIiElIoiIhISKEgIiIhhYKIiIQUCiIiElIoiIhI6P8DBd7huC4ht8kAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.recorder.plot_losses()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdl = learn.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2624/2624 [00:59<00:00, 44.34it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time_to_failure</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>seg_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>seg_00030f</th>\n",
       "      <td>5.424631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>seg_0012b5</th>\n",
       "      <td>5.698467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>seg_00184e</th>\n",
       "      <td>5.698063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>seg_003339</th>\n",
       "      <td>5.692963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>seg_0042cc</th>\n",
       "      <td>5.623507</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            time_to_failure\n",
       "seg_id                     \n",
       "seg_00030f         5.424631\n",
       "seg_0012b5         5.698467\n",
       "seg_00184e         5.698063\n",
       "seg_003339         5.692963\n",
       "seg_0042cc         5.623507"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load submission file\n",
    "submission = pd.read_csv('data/sample_submission.csv', index_col='seg_id', dtype={\"time_to_failure\": np.float32})\n",
    "\n",
    "# Load each test data, create the feature matrix, get numeric prediction\n",
    "for i, seg_id in enumerate(tqdm(submission.index)):\n",
    "#     print(i)\n",
    "    seg = pd.read_csv('data/test/' + seg_id + '.csv')\n",
    "    x = seg['acoustic_data'].values\n",
    "    \n",
    "    x, y = create_X(last_index=idx, n_steps=self.seq_len, step_length=1000)\n",
    "    x = torch.tensor(create_X(x))[None,:,:].to(torch.device('cuda'))#.view(1,-1,:)\n",
    "    pred = mdl(x).cpu().detach().numpy()[0]\n",
    "    submission.time_to_failure[i] = pred\n",
    "#     break\n",
    "\n",
    "submission.head()\n",
    "\n",
    "# # Save\n",
    "\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_lan",
   "language": "python",
   "name": "env_lan"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
